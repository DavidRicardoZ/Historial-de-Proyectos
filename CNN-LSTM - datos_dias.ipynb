{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFS0QOL6R5HC"
      },
      "source": [
        "**Importar librerías**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA1mWkRbti5X",
        "outputId": "0c3e5141-46c3-495d-fd5e-0ed5b0bfd38e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install openpyxl\n"
      ],
      "metadata": {
        "id": "yYzuFW--RC3k"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "qoJpQcdBR5HD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input, ConvLSTM2D, BatchNormalization, Flatten, Dense, Dropout, Concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "from scipy.stats import spearmanr\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZSz0rcnR5HD"
      },
      "source": [
        "**Definir parámetros**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "3CozWSKFR5HE"
      },
      "outputs": [],
      "source": [
        "# Parámetros globales\n",
        "window_days = 1      #establecer diferentes ventanas [1,2,3,5]\n",
        "rows, cols, channels = 95, 68, 1 # Reducción en la resolución de las imágenes\n",
        "n_iteraciones = 1 #aumentar hasta (10,20,30) después de las pruebas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBdTB92mR5HE"
      },
      "source": [
        "**Cargar y escalar datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "oLRDgNhhR5HE"
      },
      "outputs": [],
      "source": [
        "# Ruta del archivo de datos\n",
        "data_path = '/content/drive/MyDrive/DL_ALGAS/Datos_dias.xlsx'\n",
        "data = pd.read_excel(data_path)\n",
        "\n",
        "# Selección de columnas de entrada y salida\n",
        "input_features = ['Irradiancia', 'NO3', 'TEMP', 'pH', 'CO2 Gas']\n",
        "output_feature = 'biomasa'\n",
        "\n",
        "# Aplicar escaladores\n",
        "#scaler = StandarScaler()\n",
        "#scaler = RobustScaler()\n",
        "scaler = MinMaxScaler()\n",
        "data[input_features] = scaler.fit_transform(data[input_features])\n",
        "data[output_feature] = scaler.fit_transform(data[[output_feature]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH8ai-grR5HE"
      },
      "source": [
        "**Cargar imágenes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "iE_jdqaUR5HE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f729073-a8d7-42a8-ebc4-57401d7bf8b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de imágenes cargadas: (31, 95, 68, 1)\n"
          ]
        }
      ],
      "source": [
        "# Cargar imágenes\n",
        "image_dir = '/content/drive/MyDrive/DL_ALGAS/Datos_dias'\n",
        "all_images = [img_to_array(load_img(os.path.join(image_dir, img_name), color_mode='grayscale', target_size=(rows, cols))) / 255.0 for img_name in sorted(os.listdir(image_dir))]\n",
        "all_images = np.array(all_images)\n",
        "print(\"Total de imágenes cargadas:\", all_images.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU66lv9pR5HF"
      },
      "source": [
        "**Definir función de entrenamiento del modelo**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir función para entrenar modelo\n",
        "def train_model(data, images, window_days, n_iteraciones):\n",
        "    metrics_summary = {'R2': [], 'MSE': [], 'RMSE': [], 'MAE': [], 'Spearman': [], 'MAPE': []}\n",
        "    y_vals_all, y_preds_all = [], []\n",
        "    history_per_iteration = []\n",
        "    img_sequences = []\n",
        "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    for iteration in range(n_iteraciones):\n",
        "        img_sequences, target_sequences, feature_sequences = [], [], []\n",
        "        for i in range(len(images) - window_days + 1):\n",
        "            img_sequences.append(images[i:i + window_days])\n",
        "            target_sequences.append(data[output_feature].iloc[i + window_days - 1])\n",
        "            feature_sequences.append(data[input_features].iloc[i + window_days - 1].values)\n",
        "\n",
        "        img_sequences = np.array(img_sequences).reshape((-1, window_days, rows, cols, channels))\n",
        "        target_sequences = np.array(target_sequences)\n",
        "        feature_sequences = np.array(feature_sequences)\n",
        "\n",
        "        for train_index, val_index in kfold.split(img_sequences):\n",
        "            img_train, img_val = img_sequences[train_index], img_sequences[val_index]\n",
        "            y_train, y_val = target_sequences[train_index], target_sequences[val_index]\n",
        "            features_train, features_val = feature_sequences[train_index], feature_sequences[val_index]\n",
        "\n",
        "            # Definir el modelo CNN-LSTM con entradas adicionales\n",
        "            inp_image = Input(shape=(window_days, rows, cols, channels))\n",
        "            x = ConvLSTM2D(32, (3, 3), padding=\"same\", activation=\"tanh\", return_sequences=True)(inp_image)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = ConvLSTM2D(64, (3, 3), padding=\"same\", activation=\"tanh\", return_sequences=True)(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = ConvLSTM2D(128, (3, 3), padding=\"same\", activation=\"tanh\", return_sequences=False)(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Flatten()(x)\n",
        "\n",
        "            inp_features = Input(shape=(len(input_features),))\n",
        "            combined = Concatenate()([x, inp_features])\n",
        "\n",
        "            combined = Dense(128, activation='relu')(combined)\n",
        "            combined = Dropout(0.7)(combined)\n",
        "            combined = Dense(128, activation='relu')(combined)\n",
        "            combined = Dropout(0.3)(combined)\n",
        "            output = Dense(1, activation='linear')(combined)\n",
        "\n",
        "            model = Model(inputs=[inp_image, inp_features], outputs=output)\n",
        "            model.compile(optimizer=Adam(learning_rate=1e-4), loss=\"mse\", metrics=[\"mae\", \"mse\"])\n",
        "\n",
        "            early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "            history = model.fit([img_train, features_train], y_train, validation_data=([img_val, features_val], y_val), epochs=100, batch_size=16, callbacks=[early_stop])\n",
        "            history_per_iteration.append(history.history)\n",
        "\n",
        "            y_pred = model.predict([img_val, features_val]).flatten()\n",
        "            metrics_summary['R2'].append(r2_score(y_val, y_pred))\n",
        "            metrics_summary['MSE'].append(mean_squared_error(y_val, y_pred))\n",
        "            metrics_summary['RMSE'].append(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
        "            metrics_summary['MAE'].append(mean_absolute_error(y_val, y_pred))\n",
        "            metrics_summary['Spearman'].append(spearmanr(y_val, y_pred).correlation)\n",
        "            metrics_summary['MAPE'].append(mean_absolute_percentage_error(y_val, y_pred))\n",
        "\n",
        "            y_vals_all.append(y_val)\n",
        "            y_preds_all.append(y_pred)\n",
        "\n",
        "    avg_metrics = {metric: np.mean(scores) for metric, scores in metrics_summary.items()}\n",
        "    return {\n",
        "        'model': model,\n",
        "        'history': history_per_iteration,\n",
        "        'metrics': avg_metrics,\n",
        "        'y_val': np.concatenate(y_vals_all),\n",
        "        'y_pred': np.concatenate(y_preds_all),\n",
        "        'img_val': img_val,  # Añadir img_val para análisis de importancia\n",
        "        'features_val': features_val  # Añadir features_val para análisis de importancia\n",
        "    }"
      ],
      "metadata": {
        "id": "x_G6yr9zk_YU"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Previsualización de resultados**"
      ],
      "metadata": {
        "id": "pM7IoTnLWMeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resultados del entrenamiento\n",
        "result = train_model(data, all_images, window_days, n_iteraciones)\n",
        "\n",
        "# Previsualización de los resultados\n",
        "print(\"\\nResultados de la métrica promedio:\")\n",
        "for metric, value in result['metrics'].items():\n",
        "    print(f\"{metric}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bto3uCBaWECv",
        "outputId": "b59b5df4-1583-44d1-9e27-326cd5bebdc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 9s 2s/step - loss: 70.8881 - mae: 4.3106 - mse: 70.8881 - val_loss: 0.4686 - val_mae: 0.6590 - val_mse: 0.4686\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 360.6135 - mae: 14.1287 - mse: 360.6135 - val_loss: 0.4680 - val_mae: 0.6584 - val_mse: 0.4680\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 478.5487 - mae: 16.7234 - mse: 478.5487 - val_loss: 0.4647 - val_mae: 0.6560 - val_mse: 0.4647\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 239.0832 - mae: 13.2201 - mse: 239.0832 - val_loss: 0.4596 - val_mae: 0.6521 - val_mse: 0.4596\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 123.2621 - mae: 8.6409 - mse: 123.2621 - val_loss: 0.4520 - val_mae: 0.6463 - val_mse: 0.4520\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 194.7638 - mae: 11.0629 - mse: 194.7638 - val_loss: 0.4442 - val_mae: 0.6402 - val_mse: 0.4442\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 239.1172 - mae: 11.5901 - mse: 239.1172 - val_loss: 0.4412 - val_mae: 0.6379 - val_mse: 0.4412\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 214.7743 - mae: 9.8451 - mse: 214.7743 - val_loss: 0.4344 - val_mae: 0.6326 - val_mse: 0.4344\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 120.6996 - mae: 7.3884 - mse: 120.6996 - val_loss: 0.4186 - val_mae: 0.6200 - val_mse: 0.4186\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 87.9079 - mae: 7.2140 - mse: 87.9079 - val_loss: 0.4013 - val_mae: 0.6058 - val_mse: 0.4013\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 38.6927 - mae: 4.2785 - mse: 38.6927 - val_loss: 0.3857 - val_mae: 0.5928 - val_mse: 0.3857\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 29.2597 - mae: 3.6016 - mse: 29.2597 - val_loss: 0.3714 - val_mae: 0.5806 - val_mse: 0.3714\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 16.6066 - mae: 3.1704 - mse: 16.6066 - val_loss: 0.3583 - val_mae: 0.5692 - val_mse: 0.3583\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 33.0512 - mae: 3.8799 - mse: 33.0512 - val_loss: 0.3472 - val_mae: 0.5594 - val_mse: 0.3472\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 14.6483 - mae: 2.9378 - mse: 14.6483 - val_loss: 0.3379 - val_mae: 0.5510 - val_mse: 0.3379\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 8.5487 - mae: 1.9584 - mse: 8.5487 - val_loss: 0.3294 - val_mae: 0.5432 - val_mse: 0.3294\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 2.3933 - mae: 1.0631 - mse: 2.3933 - val_loss: 0.3219 - val_mae: 0.5362 - val_mse: 0.3219\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.4917 - mae: 0.5960 - mse: 0.4917 - val_loss: 0.3153 - val_mae: 0.5301 - val_mse: 0.3153\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 2.1376 - mae: 0.9443 - mse: 2.1376 - val_loss: 0.3103 - val_mae: 0.5254 - val_mse: 0.3103\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.6747 - mae: 0.6400 - mse: 0.6747 - val_loss: 0.3059 - val_mae: 0.5212 - val_mse: 0.3059\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3574 - mae: 0.5267 - mse: 0.3574 - val_loss: 0.3023 - val_mae: 0.5176 - val_mse: 0.3023\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3719 - mae: 0.5230 - mse: 0.3719 - val_loss: 0.2993 - val_mae: 0.5148 - val_mse: 0.2993\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.2856 - mae: 0.4575 - mse: 0.2856 - val_loss: 0.2970 - val_mae: 0.5126 - val_mse: 0.2970\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3657 - mae: 0.5161 - mse: 0.3657 - val_loss: 0.2951 - val_mae: 0.5107 - val_mse: 0.2951\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3023 - mae: 0.4834 - mse: 0.3023 - val_loss: 0.2935 - val_mae: 0.5091 - val_mse: 0.2935\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.4302 - mae: 0.5406 - mse: 0.4302 - val_loss: 0.2922 - val_mae: 0.5079 - val_mse: 0.2922\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3277 - mae: 0.4885 - mse: 0.3277 - val_loss: 0.2911 - val_mae: 0.5068 - val_mse: 0.2911\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3687 - mae: 0.5023 - mse: 0.3687 - val_loss: 0.2902 - val_mae: 0.5059 - val_mse: 0.2902\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 1.2725 - mae: 0.7440 - mse: 1.2725 - val_loss: 0.2895 - val_mae: 0.5052 - val_mse: 0.2895\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 2s 989ms/step - loss: 0.5446 - mae: 0.5767 - mse: 0.5446 - val_loss: 0.2889 - val_mae: 0.5046 - val_mse: 0.2889\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3595 - mae: 0.5067 - mse: 0.3595 - val_loss: 0.2884 - val_mae: 0.5041 - val_mse: 0.2884\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3514 - mae: 0.4993 - mse: 0.3514 - val_loss: 0.2880 - val_mae: 0.5037 - val_mse: 0.2880\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3339 - mae: 0.4936 - mse: 0.3339 - val_loss: 0.2876 - val_mae: 0.5033 - val_mse: 0.2876\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.4706 - mae: 0.5448 - mse: 0.4706 - val_loss: 0.2873 - val_mae: 0.5030 - val_mse: 0.2873\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3279 - mae: 0.4910 - mse: 0.3279 - val_loss: 0.2870 - val_mae: 0.5028 - val_mse: 0.2870\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3904 - mae: 0.5267 - mse: 0.3904 - val_loss: 0.2868 - val_mae: 0.5026 - val_mse: 0.2868\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3667 - mae: 0.5138 - mse: 0.3667 - val_loss: 0.2866 - val_mae: 0.5024 - val_mse: 0.2866\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3958 - mae: 0.5286 - mse: 0.3958 - val_loss: 0.2865 - val_mae: 0.5022 - val_mse: 0.2865\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3219 - mae: 0.4837 - mse: 0.3219 - val_loss: 0.2863 - val_mae: 0.5021 - val_mse: 0.2863\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3617 - mae: 0.5132 - mse: 0.3617 - val_loss: 0.2862 - val_mae: 0.5020 - val_mse: 0.2862\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3246 - mae: 0.4756 - mse: 0.3246 - val_loss: 0.2861 - val_mae: 0.5019 - val_mse: 0.2861\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3587 - mae: 0.5115 - mse: 0.3587 - val_loss: 0.2860 - val_mae: 0.5018 - val_mse: 0.2860\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 2s 992ms/step - loss: 0.5186 - mae: 0.5640 - mse: 0.5186 - val_loss: 0.2859 - val_mae: 0.5017 - val_mse: 0.2859\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3589 - mae: 0.4941 - mse: 0.3589 - val_loss: 0.2859 - val_mae: 0.5017 - val_mse: 0.2859\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3584 - mae: 0.5112 - mse: 0.3584 - val_loss: 0.2858 - val_mae: 0.5016 - val_mse: 0.2858\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3583 - mae: 0.5111 - mse: 0.3583 - val_loss: 0.2858 - val_mae: 0.5016 - val_mse: 0.2858\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3582 - mae: 0.5110 - mse: 0.3582 - val_loss: 0.2857 - val_mae: 0.5015 - val_mse: 0.2857\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3580 - mae: 0.5109 - mse: 0.3580 - val_loss: 0.2857 - val_mae: 0.5015 - val_mse: 0.2857\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3579 - mae: 0.5107 - mse: 0.3579 - val_loss: 0.2856 - val_mae: 0.5014 - val_mse: 0.2856\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3579 - mae: 0.5107 - mse: 0.3579 - val_loss: 0.2856 - val_mae: 0.5014 - val_mse: 0.2856\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3579 - mae: 0.5106 - mse: 0.3579 - val_loss: 0.2856 - val_mae: 0.5014 - val_mse: 0.2856\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3578 - mae: 0.5106 - mse: 0.3578 - val_loss: 0.2856 - val_mae: 0.5014 - val_mse: 0.2856\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3577 - mae: 0.5105 - mse: 0.3577 - val_loss: 0.2855 - val_mae: 0.5013 - val_mse: 0.2855\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3574 - mae: 0.5104 - mse: 0.3574 - val_loss: 0.2854 - val_mae: 0.5013 - val_mse: 0.2854\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3574 - mae: 0.5103 - mse: 0.3574 - val_loss: 0.2853 - val_mae: 0.5012 - val_mse: 0.2853\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3573 - mae: 0.5102 - mse: 0.3573 - val_loss: 0.2853 - val_mae: 0.5011 - val_mse: 0.2853\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3568 - mae: 0.5098 - mse: 0.3568 - val_loss: 0.2852 - val_mae: 0.5010 - val_mse: 0.2852\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3573 - mae: 0.5102 - mse: 0.3573 - val_loss: 0.2851 - val_mae: 0.5009 - val_mse: 0.2851\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3568 - mae: 0.5097 - mse: 0.3568 - val_loss: 0.2850 - val_mae: 0.5009 - val_mse: 0.2850\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3570 - mae: 0.5098 - mse: 0.3570 - val_loss: 0.2849 - val_mae: 0.5008 - val_mse: 0.2849\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3567 - mae: 0.5097 - mse: 0.3567 - val_loss: 0.2849 - val_mae: 0.5008 - val_mse: 0.2849\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3564 - mae: 0.5094 - mse: 0.3564 - val_loss: 0.2848 - val_mae: 0.5007 - val_mse: 0.2848\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3563 - mae: 0.5093 - mse: 0.3563 - val_loss: 0.2848 - val_mae: 0.5007 - val_mse: 0.2848\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3562 - mae: 0.5092 - mse: 0.3562 - val_loss: 0.2848 - val_mae: 0.5007 - val_mse: 0.2848\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3561 - mae: 0.5090 - mse: 0.3561 - val_loss: 0.2847 - val_mae: 0.5006 - val_mse: 0.2847\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3559 - mae: 0.5090 - mse: 0.3559 - val_loss: 0.2847 - val_mae: 0.5006 - val_mse: 0.2847\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3557 - mae: 0.5087 - mse: 0.3557 - val_loss: 0.2846 - val_mae: 0.5005 - val_mse: 0.2846\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3558 - mae: 0.5087 - mse: 0.3558 - val_loss: 0.2846 - val_mae: 0.5005 - val_mse: 0.2846\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3556 - mae: 0.5086 - mse: 0.3556 - val_loss: 0.2845 - val_mae: 0.5004 - val_mse: 0.2845\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3553 - mae: 0.5083 - mse: 0.3553 - val_loss: 0.2844 - val_mae: 0.5003 - val_mse: 0.2844\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3554 - mae: 0.5085 - mse: 0.3554 - val_loss: 0.2843 - val_mae: 0.5002 - val_mse: 0.2843\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3551 - mae: 0.5081 - mse: 0.3551 - val_loss: 0.2842 - val_mae: 0.5001 - val_mse: 0.2842\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3550 - mae: 0.5081 - mse: 0.3550 - val_loss: 0.2841 - val_mae: 0.5001 - val_mse: 0.2841\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3550 - mae: 0.5080 - mse: 0.3550 - val_loss: 0.2841 - val_mae: 0.5000 - val_mse: 0.2841\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3545 - mae: 0.5077 - mse: 0.3545 - val_loss: 0.2840 - val_mae: 0.4999 - val_mse: 0.2840\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3544 - mae: 0.5077 - mse: 0.3544 - val_loss: 0.2839 - val_mae: 0.4999 - val_mse: 0.2839\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3546 - mae: 0.5076 - mse: 0.3546 - val_loss: 0.2838 - val_mae: 0.4998 - val_mse: 0.2838\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3545 - mae: 0.5076 - mse: 0.3545 - val_loss: 0.2838 - val_mae: 0.4997 - val_mse: 0.2838\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3540 - mae: 0.5072 - mse: 0.3540 - val_loss: 0.2837 - val_mae: 0.4997 - val_mse: 0.2837\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3537 - mae: 0.5072 - mse: 0.3537 - val_loss: 0.2836 - val_mae: 0.4996 - val_mse: 0.2836\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3538 - mae: 0.5070 - mse: 0.3538 - val_loss: 0.2836 - val_mae: 0.4995 - val_mse: 0.2836\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3540 - mae: 0.5070 - mse: 0.3540 - val_loss: 0.2835 - val_mae: 0.4995 - val_mse: 0.2835\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3536 - mae: 0.5070 - mse: 0.3536 - val_loss: 0.2834 - val_mae: 0.4995 - val_mse: 0.2834\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3535 - mae: 0.5068 - mse: 0.3535 - val_loss: 0.2834 - val_mae: 0.4994 - val_mse: 0.2834\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3533 - mae: 0.5067 - mse: 0.3533 - val_loss: 0.2833 - val_mae: 0.4994 - val_mse: 0.2833\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 0.3530 - mae: 0.5063 - mse: 0.3530 - val_loss: 0.2833 - val_mae: 0.4993 - val_mse: 0.2833\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3532 - mae: 0.5063 - mse: 0.3532 - val_loss: 0.2832 - val_mae: 0.4993 - val_mse: 0.2832\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3530 - mae: 0.5063 - mse: 0.3530 - val_loss: 0.2832 - val_mae: 0.4993 - val_mse: 0.2832\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3529 - mae: 0.5062 - mse: 0.3529 - val_loss: 0.2832 - val_mae: 0.4992 - val_mse: 0.2832\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3522 - mae: 0.5056 - mse: 0.3522 - val_loss: 0.2831 - val_mae: 0.4992 - val_mse: 0.2831\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3525 - mae: 0.5058 - mse: 0.3525 - val_loss: 0.2831 - val_mae: 0.4992 - val_mse: 0.2831\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3525 - mae: 0.5059 - mse: 0.3525 - val_loss: 0.2831 - val_mae: 0.4992 - val_mse: 0.2831\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 2s 1s/step - loss: 0.3521 - mae: 0.5056 - mse: 0.3521 - val_loss: 0.2831 - val_mae: 0.4992 - val_mse: 0.2831\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 2s 877ms/step - loss: 0.3522 - mae: 0.5055 - mse: 0.3522 - val_loss: 0.2831 - val_mae: 0.4992 - val_mse: 0.2831\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 2s 920ms/step - loss: 0.3516 - mae: 0.5052 - mse: 0.3516 - val_loss: 0.2831 - val_mae: 0.4992 - val_mse: 0.2831\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 2s 850ms/step - loss: 0.3515 - mae: 0.5053 - mse: 0.3515 - val_loss: 0.2831 - val_mae: 0.4992 - val_mse: 0.2831\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 2s 853ms/step - loss: 0.3512 - mae: 0.5048 - mse: 0.3512 - val_loss: 0.2831 - val_mae: 0.4993 - val_mse: 0.2831\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 2s 885ms/step - loss: 0.3518 - mae: 0.5050 - mse: 0.3518 - val_loss: 0.2831 - val_mae: 0.4993 - val_mse: 0.2831\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 2s 902ms/step - loss: 0.3513 - mae: 0.5046 - mse: 0.3513 - val_loss: 0.2832 - val_mae: 0.4994 - val_mse: 0.2832\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 2s 895ms/step - loss: 0.3514 - mae: 0.5046 - mse: 0.3514 - val_loss: 0.2832 - val_mae: 0.4995 - val_mse: 0.2832\n",
            "1/1 [==============================] - 1s 645ms/step\n",
            "Epoch 1/100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVgGT_OoR5HF"
      },
      "source": [
        "**Exportar resultados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvQqgEXZR5HF"
      },
      "outputs": [],
      "source": [
        "# Exportar métricas a Excel\n",
        "excel_path = '/content/drive/MyDrive/DL_ALGAS/Resultados_dias.xlsx'\n",
        "with pd.ExcelWriter(excel_path) as writer:\n",
        "    df_metrics = pd.DataFrame([result['metrics']])\n",
        "    df_metrics.to_excel(writer, sheet_name=f'Ventana_{window_days}d', index=False)\n",
        "print(f'Resumen de métricas guardado en {excel_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ_2jgLfR5HG"
      },
      "source": [
        "**Generar gráficos**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráficos de resultados\n",
        "y_val = result['y_val']\n",
        "y_pred = result['y_pred']\n",
        "history = result['history']"
      ],
      "metadata": {
        "id": "dWF5OhVRQDDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Serie Temporal de Predicción vs Valores Reales\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_val, label='Valores Reales', color='blue')\n",
        "plt.plot(y_pred, label='Valores Predichos', color='orange', linestyle='--')\n",
        "plt.title(f'Predicción vs Valores Reales - Ventana {window_days} días')\n",
        "plt.xlabel('Índice')\n",
        "plt.ylabel('Biomasa')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gda_qLYFQJ2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de Dispersión de Predicción vs Real\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(y_val, y_pred, c=np.abs(y_val - y_pred), cmap='viridis', s=70, alpha=0.9, edgecolor='black')\n",
        "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'k--', lw=2)\n",
        "plt.title(f'Valores Reales vs. Predichos - Ventana {window_days} días')\n",
        "plt.xlabel('Valores Reales de Biomasa')\n",
        "plt.ylabel('Valores Predichos de Biomasa')\n",
        "cbar = plt.colorbar(scatter)\n",
        "cbar.set_label('Error Absoluto')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "atGvy7v3QMZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de Error Residual\n",
        "residuals = y_val - y_pred\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_val, residuals, alpha=0.6, color=\"purple\")\n",
        "plt.axhline(0, linestyle='--', color='black')\n",
        "plt.title(f'Errores Residuales - Ventana {window_days} días')\n",
        "plt.xlabel('Valores Reales de Biomasa')\n",
        "plt.ylabel('Error Residual')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VOAc8LjRQOTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograma de Errores\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(residuals, bins=20, color=\"darkblue\", edgecolor='black')\n",
        "plt.title(f'Distribución de Errores - Ventana {window_days} días')\n",
        "plt.xlabel('Error Residual')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_CeThoqkQSQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Curva de Aprendizaje\n",
        "plt.figure(figsize=(10, 6))\n",
        "for fold_history in history:\n",
        "    # Verificar si ya existe una leyenda\n",
        "    legend = plt.gca().get_legend()\n",
        "\n",
        "    # Agregar etiquetas solo si aún no existen\n",
        "    if legend is None or 'Entrenamiento' not in [text.get_text() for text in legend.get_texts()]:\n",
        "        plt.plot(fold_history['loss'], color='blue', alpha=0.3, label='Entrenamiento')\n",
        "    else:\n",
        "        plt.plot(fold_history['loss'], color='blue', alpha=0.3)\n",
        "\n",
        "    if legend is None or 'Validación' not in [text.get_text() for text in legend.get_texts()]:\n",
        "        plt.plot(fold_history['val_loss'], color='orange', alpha=0.3, label='Validación')\n",
        "    else:\n",
        "        plt.plot(fold_history['val_loss'], color='orange', alpha=0.3)\n",
        "\n",
        "plt.title(f'Curva de Aprendizaje - Ventana {window_days} días')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_nCjbsPfQTJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de Importancia de Variables (Análisis de Sensibilidad)\n",
        "importances = []\n",
        "X = data[input_features].values  # Usar las columnas de características de entrada\n",
        "X_val = X[:len(y_val)]  # Ajustar el tamaño para el conjunto de validación\n",
        "\n",
        "for feature_idx in range(X.shape[1]):\n",
        "    X_temp = X_val.copy()\n",
        "    X_temp[:, feature_idx] = np.mean(X[:, feature_idx])  # Perturbar la variable\n",
        "    perturbed_pred = result['model'].predict([img_val, X_temp]).flatten()\n",
        "    importance = mean_absolute_error(y_val, perturbed_pred)\n",
        "    importances.append(importance)\n",
        "\n",
        "# Gráfico de Importancia de Características\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=input_features, y=importances, palette=\"viridis\")\n",
        "plt.title(f'Importancia de Variables - Ventana {window_days} días')\n",
        "plt.xlabel('Variables Ambientales')\n",
        "plt.ylabel('Importancia (MAE)')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_IhxosMEQVUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Heatmap de Correlación entre Variables\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(data[input_features + [output_feature]].corr(), annot=True, cmap=\"YlGnBu\")\n",
        "plt.title(f\"Heatmap de Correlación entre Variables\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MPu3eRf6QX-p"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}